{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20975a5a-c35b-4f96-b5f0-45ba47aa46c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests \n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053b0bc9-6635-4a4f-b57d-b6ddc1c36a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '04-monitoring/data/results-gpt4o-mini.csv'\n",
    "url = f'{base_url}/{relative_url}?raw=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b36337-b9a2-48ee-897a-3f94ac4d787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c444cc4-f21f-4219-bed4-f2113d66115e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2545b503-0c2b-4598-b2d5-df00308480d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\encode\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ahmed\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-mpnet-base-dot-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d31d39-77df-4633-b963-25e6c407cc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can sign up for the course by visiting the course page at [http://mlzoomcamp.com/](http://mlzoomcamp.com/).'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm = df.iloc[0].answer_llm\n",
    "answer_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd09f8-fe30-4084-990f-37b42450b96e",
   "metadata": {},
   "source": [
    "<b> Q1. Getting the embeddings model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bb37394-3023-49a3-90db-164ce1736c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42244673, -0.22485629, -0.32405835, -0.2847585 ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.encode(answer_llm)[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c390c05-0e57-4e97-8bf1-1da8dc6d5878",
   "metadata": {},
   "source": [
    "<b> Q2. Computing the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e23a2-f7db-4255-bd4b-4364b3828fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1dc9a25-a901-4603-9487-2fe1194c5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pair = df[['answer_llm','answer_orig']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36b6f4e8-c306-4d5a-a118-9fb7ff46843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record, model):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_orig = model.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1c867cf-28f9-4ad0-9fc7-384509d38bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1830/1830 [10:05<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "for record in tqdm(results_pair):\n",
    "    sim = compute_similarity(record, embedding_model)\n",
    "    similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "645d8882-9c6a-49a6-adfb-7280b97c7f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean       28.015772\n",
       "std         6.413295\n",
       "min         3.511811\n",
       "25%        24.631171\n",
       "50%        28.897566\n",
       "75%        32.389799\n",
       "max        44.296772\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine'] = similarity\n",
    "df['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "990c58b5-6c7c-4fb1-a586-3f3d8af60acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vec(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    v_norm = v / norm\n",
    "    return v_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "277810aa-4a71-4563-a151-cf9cda369b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_normalized(record, model):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = normalize_vec(model.encode(answer_llm))\n",
    "    v_orig = normalize_vec(model.encode(answer_orig))\n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "961262dc-da8d-49f0-abcc-6c8162eec7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1830/1830 [09:43<00:00,  3.13it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity_norm = []\n",
    "\n",
    "for record in tqdm(results_pair):\n",
    "    sim = compute_cosine_normalized(record, embedding_model)\n",
    "\n",
    "    similarity_norm.append(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b40e524d-a5fa-4d54-9d54-e3fccc332c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean        0.738963\n",
       "std         0.156405\n",
       "min         0.090286\n",
       "25%         0.655194\n",
       "50%         0.772145\n",
       "75%         0.853112\n",
       "max         0.993684\n",
       "Name: cosine_norm, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine_norm'] = similarity_norm\n",
    "df['cosine_norm'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e03cec9-4272-46f6-9be4-26908a6c5aad",
   "metadata": {},
   "source": [
    "<b> Q4. Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c4af7d8-4653-4888-a157-048198581438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\ahmed\\anaconda3\\envs\\encode\\lib\\site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "40230b7f-5cc5-4bcd-bad3-6ecfd9a649b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_llm     Yes, you can ask your questions in advance if ...\n",
       "answer_orig    Everything is recorded, so you won’t miss anyt...\n",
       "document                                                5170565b\n",
       "question       Can I ask questions in advance if I can't atte...\n",
       "course                                 machine-learning-zoomcamp\n",
       "cosine_norm                                             0.783566\n",
       "cosine                                                 31.441833\n",
       "Name: 11, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8546213-ec81-48c2-bd6c-9d65481d5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm_10 = df.iloc[11]['answer_llm']\n",
    "answer_orig_10 = df.iloc[11]['answer_orig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4333518e-50af-42ab-959d-c5d25ac2576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "scores = rouge_scorer.get_scores(df.iloc[11]['answer_llm'], df.iloc[11]['answer_orig'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125028d4-f59c-498e-a8ee-d59379ab4521",
   "metadata": {},
   "source": [
    "There are three scores: rouge-1, rouge-2 and rouge-l, and precision, recall and F1 score for each.\n",
    "<br>rouge-1 - the overlap of unigrams,\n",
    "<br>rouge-2 - bigrams,\n",
    "<br>rouge-l - the longest common subsequence\n",
    "<br>https://klu.ai/glossary/rouge-score\n",
    "<br>https://medium.com/@sthanikamsanthosh1994/understanding-bleu-and-rouge-score-for-nlp-evaluation-1ab334ecadcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d091c165-b880-41d5-8f81-01ae05e977d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.6060606060606061,\n",
       "  'p': 0.6060606060606061,\n",
       "  'f': 0.6060606010606061},\n",
       " 'rouge-2': {'r': 0.43243243243243246,\n",
       "  'p': 0.41025641025641024,\n",
       "  'f': 0.42105262658241},\n",
       " 'rouge-l': {'r': 0.5757575757575758,\n",
       "  'p': 0.5757575757575758,\n",
       "  'f': 0.5757575707575758}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5921a707-6983-416b-9c6c-022ee2b063b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060606010606061"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What's the F score for rouge-1?\n",
    "scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d3f8f-2f34-4502-84c7-b051bc534844",
   "metadata": {},
   "source": [
    "<b> Q5. Average rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b88ccf8-0b5a-4eec-abb9-893e6a68a848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5342902661335307"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "av_score = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f'])/3\n",
    "av_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a609e-38de-4349-b918-1a44dea47cd7",
   "metadata": {},
   "source": [
    "<b> Q6. Average rouge score for all the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62d3127e-f045-465e-bcce-192a347b8729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.061224489795918366,\n",
       "  'p': 0.21428571428571427,\n",
       "  'f': 0.09523809178130524},\n",
       " 'rouge-2': {'r': 0.017543859649122806,\n",
       "  'p': 0.07142857142857142,\n",
       "  'f': 0.028169010918468917},\n",
       " 'rouge-l': {'r': 0.061224489795918366,\n",
       "  'p': 0.21428571428571427,\n",
       "  'f': 0.09523809178130524}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "26afacaa-1a8e-44e1-a146-9a7f88198395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0, 'p': 0, 'f': 0},\n",
       " 'rouge-2': {'r': 0, 'p': 0, 'f': 0},\n",
       " 'rouge-l': {'r': 0, 'p': 0, 'f': 0}}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_scores = {key: {'r': 0, 'p': 0, 'f': 0} for key in scores}\n",
    "total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1f4ebc1f-6cc6-43d4-81e6-19a6ea535d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1830/1830 [00:05<00:00, 313.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for record in tqdm(results_pair):   \n",
    "    scores = rouge_scorer.get_scores(record['answer_llm'], record['answer_orig'])[0]\n",
    "    total_scores['rouge-1']['f'] += scores['rouge-1']['f']\n",
    "    total_scores['rouge-2']['f'] += scores['rouge-2']['f']\n",
    "    total_scores['rouge-l']['f'] += scores['rouge-l']['f']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "919508de-6312-4165-9118-f01309ed0b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0, 'p': 0, 'f': 643.6012007368518},\n",
       " 'rouge-2': {'r': 0, 'p': 0, 'f': 323.39219597819846},\n",
       " 'rouge-l': {'r': 0, 'p': 0, 'f': 599.4817512725124}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8b6b71cb-5474-4ad3-bfee-8ec1cc7ad6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1767170469826221"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What's the agerage rouge_2 across all the records?\n",
    "rouge_2_av = total_scores['rouge-2']['f']/len(results_pair)\n",
    "rouge_2_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca23d82-d402-4e7f-a94d-362621826618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
